{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ass3 Live Programming - Classifier Evaluation\n",
    "### Important:\n",
    "* #### Read the entire task description before starting\n",
    "* #### Do only what is asked\n",
    "* #### You find documentation for the provided components below\n",
    "\n",
    "### Task:\n",
    "* #### Your task is to evaluate the performance of various classifiers (given in `classifiers`) for classifying PCA-transformed MNIST images with different numbers of PCA features.\n",
    "  * The classifiers' interfaces are documented below.\n",
    "  * Do not hardcode (or copy-paste) the code for the individual classifiers. Your function `evaluate` should work with arbitrary dictionaries of the same structure.\n",
    "* #### The data loaded is already PCA-transformed, it has the same structure as always (feature_matrix: num_samples x num_features, label_vector: num_samples)\n",
    "* #### Create an evaluation as shown in the plot below (plots just have to be there and don't have to be as beautiful as ours :P): \n",
    "  * The crosses (X) mark the highest accuracy for each classifier. You might want to use `np.argmax` (\"Returns the indices of the maximum values along an axis.\") to find the number of features corresponding to the highest accuracy.\n",
    "  * Let `evaluate` return a dictionary containing the best number of features and corresponding accuracy for each classifier as a tuple, eg.:\n",
    "  ```python\n",
    "  {'euclidean_5nn': (50, 0.88),\n",
    "    'cosine_5nn': (100, 0.89),\n",
    "    'tree': (6, 0.69),\n",
    "    'svc': (20, 0.93)}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All classifiers provide the following interfaces:\n",
    "\n",
    "```\n",
    "Classifier.fit(self, X, y)\n",
    "    \"\"\"Fits the model to the given training data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        training features\n",
    "    y : np.ndarray\n",
    "        training labels\n",
    "    \"\"\"\n",
    "    \n",
    "Classifier.score(self, X, y)\n",
    "    \"\"\"Return the global accuracy of the given test data and labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        testina features\n",
    "    y : np.ndarray\n",
    "        testina labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "        Mean accuracy of the prediction.\n",
    "```\n",
    "\n",
    "#### Lineplots can be created like this\n",
    "```python\n",
    "lineplot = hv.Curve((x_data, y_data))\n",
    "```\n",
    "#### To add a label, use\n",
    "```python\n",
    "lineplot = hv.Curve((x_data, y_data), label=\"whatever\")\n",
    "```\n",
    "#### Scatterplots can be created like this\n",
    "```python\n",
    "scatterplot = hv.Scatter((x_data, y_data))\n",
    "scatterplot = hv.Scatter((x_data, y_data)).opts(size=20, marker=\"x\", color=\"k\") # to create nice big X's\n",
    "```\n",
    "#### And combined into an overlay using hv.Overlay, or by multiplying them\n",
    "```python\n",
    "overlay = hv.Overlay(list_of_plots)\n",
    "overlay = plot1 * plot2\n",
    "```\n",
    "#### Plots can be placed next to each other using hv.Layout from a list, or by adding them\n",
    "```python\n",
    "layout = hv.Layout(list_of_plots)\n",
    "layout = plot_or_layout + plot_or_layout\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this to import the provided components\n",
    "import pickle\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import numpy as np\n",
    "import holoviews as hv\n",
    "hv.extension(\"bokeh\")\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"image_pca.p\", \"rb\") as pf:\n",
    "    (X_train, y_train), (X_test, y_test) = pickle.load(pf)\n",
    "    # X_train.shape -> (num_train_samples, num_features)\n",
    "    # y_train.shape -> (num_train_samples,)\n",
    "    # X_test.shape  -> (num_test_samples, num_features)\n",
    "    # y_test.shape  -> (num_test_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"euclidean_5nn\" : KNeighborsClassifier(n_neighbors=5, metric=\"euclidean\"),\n",
    "    \"cosine_5nn\" : KNeighborsClassifier(n_neighbors=5, metric=\"cosine\"),\n",
    "    \"tree\": DecisionTreeClassifier(),\n",
    "    \"svc\": SVC(),\n",
    "}\n",
    "\n",
    "\n",
    "num_features = [1,2,3,4,5,6,7,8,9,10,20,30,40,50,100]\n",
    "def evaluate(classifiers, X_train, y_train, X_test, y_test, num_dims):\n",
    "    # YOUR CODE GOES HERE:\n",
    "    \n",
    "    for clf in classifier.keys():\n",
    "        classifiers[clf]\n",
    "    pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
